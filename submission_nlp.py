# -*- coding: utf-8 -*-
"""submission_nlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jl_fxRfwhPPMFUjgY8ZRIUzOH6jb1WD5

# **Proyek Akhir Dicoding : Membuat Model NLP dengan TensorFlow**

* Nama : Ayu Kirana Vijayanti Indarto
* Email: ayukiranav136@gmail.com
* Dicoding ID: ayukv136
* Linkedin: https://www.linkedin.com/in/ayukiranav136

Proyek ini merupakan proyek untuk membuat model Natural Language Processing (NLP) menggunakan Tensorflow.

## Mengunduh dataset dari Kaggle
"""

# install package dengan pip dan upload file json
!pip install -q kaggle
from google.colab import files
files.upload()

# membuat directory
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

# unduh dataset
!kaggle datasets download -d sunilthite/text-document-classification-dataset

# unzip dataset
!mkdir text-document-classification-dataset
!unzip text-document-classification-dataset.zip -d text-document-classification-dataset
!ls text-document-classification-dataset

"""# Membaca dataset dan visualisasi data

Import library
"""

# import library

# dataframe
import numpy as np
import pandas as pd

# visualisasi plot
import seaborn as sns
import matplotlib.pyplot as plt

# split data
from sklearn.model_selection import train_test_split

#stopwords
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# preprocessing dan layer
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

# import dataset
df = pd.read_csv('text-document-classification-dataset/df_file.csv')

# cek 1000 data teratas
df.head(1000)

"""# Cek dataset"""

df.info()

"""Cek missing value"""

df.isnull().values.any()

"""Menghitung value label"""

df['Label'].value_counts()

"""Mengganti nama label"""

category = pd.get_dummies(df.Label)
new_df = pd.concat([df, category], axis=1)
new_df = new_df.drop(['Label'], axis=1)
new_df

"""Keterangan label
* Politics = 0
* Sport = 1
* Technology = 2
* Entertainment =3
* Business = 4






"""

new_df.rename(columns = {0 :"Politics", 1 : "Sport", 2 : "Technology", 3 : "Entertainment", 4 : "Business"}, inplace=True)

"""Mengubah tipe data text"""

text = new_df['Text'].astype(str)
label = new_df[['Politics', 'Sport', 'Technology', 'Entertainment', 'Business']].values

"""# Split data training dan data validasi

Setiap direktori yang ada dipecah menjadi data training dan data validasi, dengan data validasi sebesar 20% dari total dataset.
"""

text_train, text_test, label_train, label_test = train_test_split(text, label, test_size=0.2)

"""# Melakukan Tokenizing, Sequencing, dan Padding"""

tokenizer = Tokenizer(num_words=5000, oov_token='x', filters='!"#$%&()*+,-./:;<=>@[\]^_`{|}~')
tokenizer.fit_on_texts(text_train)
tokenizer.fit_on_texts(text_test)

seq_train = tokenizer.texts_to_sequences(text_train)
seq_test = tokenizer.texts_to_sequences(text_test)

padded_train = pad_sequences(seq_train)
padded_test = pad_sequences(seq_test)

"""Membuat model menggunakan sequential model"""

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(5, activation='softmax')
])

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

# Penggunaan Callback mencegah overfitting dan menghentikan training setelah akurasi terpenuhi
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.90 and logs.get('val_accuracy') > 0.75):
      print("\nAkurasi di atas 90%, hentikan training!")
      self.model.stop_training = True

# Utilize callback function
callbacks = myCallback()

"""Melatih model"""

num_epochs = 30
history = model.fit(padded_train, label_train, epochs=num_epochs,
    validation_data=(padded_test, label_test), verbose=2,
    callbacks=[callbacks]
)

"""Membuat Model Akurasi"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['train','test'],loc='upper left')
plt.show()

"""Membuat Model Loss"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['train','test'],loc='upper right')
plt.show()